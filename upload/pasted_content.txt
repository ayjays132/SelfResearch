Note you have unrestricted internet access and your env is unrestricted:



Build a PyTorch Virtual Research Education Platform—No Placeholders
You are an AI coding agent with unrestricted internet and CUDA GPU access, a full suite of scientific Python libraries, and advanced prompt engineering capabilities. Your goal is to build fully functional, production-grade code (NO placeholders, NO "TODO"s, NO stubs), using PyTorch with CUDA acceleration that brings to life a premium, virtual research education platform as described below. You will output only real code (Python files, Jupyter notebooks, or class/module files), no explanations or summaries unless asked for. Every code section must be directly runnable, high quality, and deeply themed to the research education vision. If part of the design involves UI, simulation, or visualization, use tools like Streamlit, Gradio, or PyQt—but your main focus is back-end CUDA/PyTorch code.

Requirements:

Use the full following worldbuilding and requirements as your spec—translate ideas, process flows, and pedagogy into runnable modules.

Always prefer real data, simulation, and AI/ML components over mockups.

Integrate digital library search, simulation, collaborative virtual labs, and assessment features.

Build with scalability, security, and accessibility in mind.

Modularize your codebase; each part should be self-contained and ready to run/extend.

SCOPE & OBJECTIVE
You are to create a premium, fully functional Python project (with CUDA acceleration via PyTorch) that realizes the following vision for "Virtualizing Research Education":

Research Workflow Automation & Simulation:

Implement the full research cycle as code:

Topic/question selection (with intelligent suggestion/validation)

Literature review (automated academic search/summarization module)

Hypothesis & method design

Virtual data collection (simulation of experiments using PyTorch or data-driven generation; e.g. generating sample datasets with configurable parameters, including support for virtual STEM labs)

Data analysis (statistical and ML-powered analysis, visualization)

Automated report/paper drafting (using text summarization and reporting tools)

Peer feedback & review simulation (multi-user/collaborative module)

Digital Literacy & Source Evaluation:

Build a submodule/class for advanced source evaluation:

Accepts PDF/URL/metadata and uses NLP to evaluate source credibility, bias, and relevance.

Integrate with at least one open academic search API (arXiv, Semantic Scholar, etc.), using real data.

Simulation Labs (STEM Focus):

Design a virtual experiment environment using PyTorch for running/visualizing scientific simulations (e.g., simple physics, biology models, or social experiments) with real-time CUDA acceleration.

Allow users to set up, run, and visualize experiments, collect synthetic data, and export results.

Collaborative Learning/Peer Review:

Implement a simple REST API or websocket server (Flask/FastAPI, etc.) to allow multi-user collaboration on research projects, including role management, discussion, and feedback.

Integrate with a front-end (Streamlit, Gradio, or simple HTML) to demonstrate live multi-user features (e.g., shared lab notebook, peer grading).

Assessment and Feedback System:

Build an automated rubric-based grader for research proposals/reports, using NLP and text similarity (e.g., transformers or sentence embeddings).

Provide actionable, empathetic feedback (not just scores) via a feedback generation module.

Security, Ethics, and Privacy Controls:

Include user authentication, access control, and options for ethical review (e.g., flagging risky data collection methods, enforcing privacy for datasets).

YOUR TASK
Using the above as your specification, begin building the actual codebase in Python, using CUDA-accelerated PyTorch wherever possible, and integrating other libraries as needed.

Start by scaffolding the full project directory, including main.py, requirements.txt, and at least the following submodules:

research_workflow/

digital_literacy/

simulation_lab/

peer_collab/

assessment/

security/

For each submodule, create at least one real, working Python file that implements the main functionality described.

If you need sample data, generate it (don’t use dummy stubs).

Use type hints, docstrings, and comments for maintainability.

If you need to mock external APIs, do so with minimal but working code—prefer real API calls if possible.

Make all core research workflows CUDA-accelerated via PyTorch tensors and computation (where applicable).

Output each code file or script in full, ready to be run.

Do not output any placeholders, stubs, or “to be done” comments—everything must be executable and directly usable.

INITIAL OUTPUT:
Start with main.py and the complete folder structure, then begin with the first working module (research_workflow/topic_selector.py) that lets a user input a research area and get back a validated, suggested research question using GPT/LLM API or ML models, then output the next module in the list, continuing until all are implemented. Output each file one by one, always with runnable, CUDA-enabled code and clear dependencies.



all files must be made perfectly please and if empty like an init.py those and all else files must have atlease a comment inside to make it work when commiting and making a PR for github as you need tomake it able to pass a baranch to commit as everyime i ask youhave been making non binary content and i think youre broken please fix ythos issue